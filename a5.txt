Script started on 2022-11-18 01:39:19-05:00
shivam@sjsu:/mnt/scratch/shivam/A5[shivam@sjsu A5]$ history -c
shivam@sjsu:/mnt/scratch/shivam/A5[shivam@sjsu A5]$ vi author_to_tweeter.sh

========================================================================
SHELL SCRIPT THAT TAKES:
THE A FILE WITH AUTHOR \t RETWEETER/REPLIER
OUTPUT FILE
FILE THAT CONTAINS ALL OF THE TWEETS BY THE REPLIER OR RETWEETER
========================================================================
"author_to_tweeter.sh"  [New File]
-- INSERT --
#!/bin/bash
if [ -z "$1" ]
then
        echo "\$1 is empty: input file of author with tweeter"
else
        if [ -z "$2" ]
        then
                echo "\$2 is empty: output file"
        else
                if [ -z "$3" ]
                then
                        echo "\$3 is empty: dataset is empty"
                else
                                count_hashtags_entire_dataset=$(wc -l hashtags.txt | awk -F " " '{print $1}')
                        awk -F "\t" '{print $4}' $3 | tr ',' '\n' | tr -d '\"'   | tr '[:upper:]' '[:lower:]' | sed '/^$/d'| sort | uniq > temp.txt
                        count_hashtags_in_C=$(wc -l temp.txt | awk -F " " '{print $1}')
                        cat temp.txt | while IFS= read -r hashtag
                        do
                                count_H_entire_dataset=$(grep -Pi "\t$hashtag\t|\"$hashtag,|,$hashtag,|,$hashtag\"" downloaded_tweets_extend_original_nolf2_NOBOT.tsv | wc -l)
                                count_H_in_C=$(grep -Pi "\t$hashtag\t|\"$hashtag,|,$hashtag,|,$hashtag\"" $3 | wc -l)
                                frequency_H_overall=$(bc <<< "scale=6;$count_H_entire_dataset/$count_hashtags_entire_dataset")
                                frequency_H_in_C=$(bc <<< "scale=6;$count_H_in_C/$count_hashtags_in_C")
                                relative_frequency_H_C=$(bc <<< "scale=6;$frequency_H_in_C/$frequency_H_overall")
                                cluster_C_leader=$(grep -Pi "\t$hashtag\t|\"$hashtag,|,$hashtag,|,$hashtag\"" $3| awk -F "\t" '{print $2}' | sort | uniq -c | sort -nr | awk -F " " '{print $2}' | head -n 1)
                                echo -e "$hashtag\t$cluster_C_leader\t$relative_frequency_H_C\t$frequency_H_in_C\t$frequency_H_overall\t$count_H_in_C\t$count_hashtags_in_C\t$count_H_entire_dataset\t$count_hashtags_entire_dataset" >> $2
                        done
                        rm temp.txt
                fi
        fi
fi

"author_to_tweeter.sh" [New] 30L, 1950C written

shivam@sjsu:/mnt/scratch/shivam/A5[shivam@sjsu A5]$ chmod 777 author_to_tweeter.sh

========================================================================
CREATE HEADERS FOR BOTH FILES
========================================================================
shivam@sjsu:/mnt/scratch/shivam/A5[shivam@sjsu A5]$ echo -e "hashtag_H\tcluster_C_leader(userID)\trelative_frequency_H_C\tfrequency_H_in_C\tfrequency
y_H_overall\tcount_H_in_C\tcount_hashtags_in_C\tcount_H_entire_dataset\tcount_hashtags_entire_dataset retweets_hashtag_freqs.tsv" > retweets_hashtag_freqs.tsv

shivam@sjsu:/mnt/scratch/shivam/A5[shivam@sjsu A5]$ cat retweets_hashtag_freqs.tsv > replies_hashtag_freqs.tsv

========================================================================
FILE WITH ALL TWEETS
========================================================================
shivam@sjsu:/mnt/scratch/shivam/A5[shivam@sjsu A5]$ awk -F "\t" 'NR==FNR {id[$2]=$1; id[$1]=$2; next } ($2 in id && $6 in id) {print $0}' 3_or_more_replies.tsv downloaded_tweets_extend_original_nolf2_NOBOT.tsv > replies_in_C

========================================================================
ALL HASHTAGS IN DATASET
========================================================================
shivam@sjsu:/mnt/scratch/shivam/A5[shivam@sjsu A5]$ awk -F "\t" '{print $4}' downloaded_tweets_extend_original_nolf2_NOBOT.tsv | tr ',' '\n' | tr -d 
 '\"'   | tr '[:upper:]' '[:lower:]' | sed '/^$/d'| sort | uniq > hashtags.txt

========================================================================
CALL SCRIPT FOR REPLIES
========================================================================
shivam@sjsu:/mnt/scratch/shivam/A5[shivam@sjsu A5]$ ./author_to_tweeter.sh 3_or_more_replies replies_hashtag_freqs.tsv replies_in_C

shivam@sjsu:/mnt/scratch/shivam/A5[shivam@sjsu A5]$ sort -nrk 3 replies_hashtag_freqs.tsv | head -n 5
solidaritätmitkarl	877968869138329601	25.390909	.002793	.000110	2	716	2	18162
poems	1497454353090809860	25.390909	.002793	.000110	2	716	2	18162
oz	3270007519	25.390909	.002793	.000110	2	716	2	18162
kindleunlimited	1497454353090809860	25.390909	.002793	.000110	2	716	2	18162
godslaw	4830874006	25.390909	.002793	.000110	2	716	2	18162

========================================================================
GET ALL RETWEETED TWEETS FROM CLUSTERS
========================================================================
shivam@sjsu:/mnt/scratch/shivam/A5[shivam@sjsu A5]$ grep retweeted downloaded_tweets_extend_nolf2_NOBOT.tsv | sed "s/\[<ReferencedTweet id=//g" | sed
d "s/ type=retweeted\]//g" | awk -F '\t' '{print $1 "\t" $5}' | sort | uniq > rtID_to_ogID.tsv 

shivam@sjsu:/mnt/scratch/shivam/A5[shivam@sjsu A5]$ cut -f 2 rtID_to_ogID.tsv > retweeted_ids.txt

shivam@sjsu:/mnt/scratch/shivam/A5[shivam@sjsu A5]$ fgrep -f retweeted_ids.txt downloaded_tweets_extend_original_nolf2_NOBOT.tsv | awk -F "\t" '{prin
nt $2}' > userids_retweets3_fgrep.txt

shivam@sjsu:/mnt/scratch/shivam/A5[shivam@sjsu A5]$ fgrep -f userids_retweets3_fgrep.txt downloaded_tweets_extend_original_nolf2_NOBOT.tsv  | cut -f 
 1,2 > ogID_to_userID.tsv

shivam@sjsu:/mnt/scratch/shivam/A5[shivam@sjsu A5]$ awk -F "\t" '{print $1}' ogID_to_userID.tsv > original_tweet_ID

shivam@sjsu:/mnt/scratch/shivam/A5[shivam@sjsu A5]$ grep retweeted downloaded_tweets_extend_nolf2_NOBOT.tsv | sed "s/\[<ReferencedTweet id=//g" | sed
d "s/ type=retweeted\]//g" | grep -Ff original_tweet_ID > all_retweeted_tweets

shivam@sjsu:/mnt/scratch/shivam/A5[shivam@sjsu A5]$ tail -n +2 original_tweet_ID > original_tweet_ID

shivam@sjsu:/mnt/scratch/shivam/A5[shivam@sjsu A5]$ awk -F "\t" 'NR==FNR {id[$1]=$1; id[$2]=$2; next } ($5 in id) {$5 = id[$2]; print $1 "\t" $2 "\t"
" $3 "\t" $4 "\t" $5}' ogID_to_userID.tsv all_retweeted_tweets > rt_auth.tsv

shivam@sjsu:/mnt/scratch/shivam/A5[shivam@sjsu A5]$ awk -F "\t" 'NR==FNR {id[$1]=$1; id[$2]=$2; next } ($5 in id && $2 in id) {print $1 "\t" $2 "\t" $3 "\t" $4 "\t" $5}' 3_or_more_retweets.tsv rt_auth.tsv > retweets_in_C

shivam@sjsu:/mnt/scratch/shivam/A5[shivam@sjsu A5]$ head -n 2 retweets_in_C 
1520436665797517312	1921951394	2022-04-30 16:15:24+00:00		1921951394
1520230313187758082	1921951394	2022-04-30 02:35:25+00:00	IdahoGOP	1921951394

========================================================================
CALL SCRIPT FOR RETWEETS
========================================================================

shivam@sjsu:/mnt/scratch/shivam/A5[shivam@sjsu A5]$ ./author_to_tweeter.sh 3_or_more_retweets.tsv retweets_hashtag_freqs.tsv retweets_in_C

shivam@sjsu:/mnt/scratch/shivam/A5[shivam@sjsu A5]$ sort -nrk 3 retweets_hashtag_freqs.tsv | head -n 5
thankyoutom	1921951394	11.254545	.000619	.000055	2	3227	1	18162
sometimesyourgcomeout	1921951394	11.254545	.000619	.000055	2	3227	1	18162
shameonrebuplicans	1921951394	11.254545	.000619	.000055	2	3227	1	18162
sendstingers	1921951394	11.254545	.000619	.000055	2	3227	1	18162
sendjavelins	1921951394	11.254545	.000619	.000055	2	3227	1	18162

========================================================================
SAVE HISTORY
========================================================================
shivam@sjsu:/mnt/scratch/shivam/A5[shivam@sjsu A5]$ history > cmds.log
shivam@sjsu:/mnt/scratch/shivam/A5[shivam@sjsu A5]$ exit

Script done on 2022-11-18 01:44:24-05:00

Overall I didn’t notice too many hashtags that were used way more in the cluster than in the entire dataset
